{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612ed84-2093-47f7-b7b1-ff1a461c99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai langchain chromadb pypdf sentence-transformers yt_dlp pydub librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f105ea8-16e2-4682-9212-687036bf60e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/ZV-fcq-DIuE\n",
      "[youtube] ZV-fcq-DIuE: Downloading webpage\n",
      "[youtube] ZV-fcq-DIuE: Downloading ios player API JSON\n",
      "[youtube] ZV-fcq-DIuE: Downloading android player API JSON\n",
      "[youtube] ZV-fcq-DIuE: Downloading m3u8 information\n",
      "[info] ZV-fcq-DIuE: Downloading 1 format(s): 140\n",
      "[download] yt-audios//World Cup ｜ India's mid-tournament review ft. Harsha Bhogle.m4a has already been downloaded\n",
      "[download] 100% of    4.09MiB\n",
      "[ExtractAudio] Not converting audio yt-audios//World Cup ｜ India's mid-tournament review ft. Harsha Bhogle.m4a; file is already in target format m4a\n",
      "Transcribing part 1!\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - load documents\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "import openai\n",
    "\n",
    "urls = [\"https://youtu.be/ZV-fcq-DIuE\"]\n",
    "\n",
    "# Directory to save audio files\n",
    "save_dir = \"yt-audios/\"\n",
    "\n",
    "# Setting the openai API key for the WhisperParser\n",
    "api_key = \"<YOUR API KEY HERE>\"\n",
    "openai.api_key = api_key\n",
    "\n",
    "loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1825794e-1e6a-4a71-ba40-5e97502b3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - split documnets into chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99c9774-2d26-43a3-8fac-a067f98c11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - load documents into Chroma using the open-source embedding function\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb54331-de1b-4be0-b43c-95909810161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - define the LLM model\n",
    "\n",
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, \n",
    "                 temperature=0, \n",
    "                 openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df75ddce-2b8b-45e1-8609-f102327de816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - create the chain with the LLM model and the database\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=db.as_retriever(), \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f6ee1d3-7d06-4c73-b825-bac7b2e63276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the given context, it is mentioned that India has won five matches in the 2023 cricket world cup. \n",
       "\n",
       "The top three players based on the given context are:\n",
       "\n",
       "1. Rohit Sharma: Rohit is mentioned as the captain who is setting the platform for the team's batting and keeping the atmosphere right.\n",
       "2. Virat Kohli: Virat is praised for his contributions in the last two chases and his ability to carry the team through in successive games.\n",
       "3. Jasprit Bumrah: Bumrah is highlighted as the catalyst for the bowling unit, delivering excellent first spells and maintaining low economy rates."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6 - ask the question and display the response!\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "prompt = \"Tell me how many matches have India won in the 2023 cricket world cup. Also, list the top 3 players based on given context\"\n",
    "response = retrievalQA.run(prompt)\n",
    "\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

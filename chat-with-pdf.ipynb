{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612ed84-2093-47f7-b7b1-ff1a461c99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai langchain chromadb pypdf sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca1b6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 - fetch OpenAI API key from the environment\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f105ea8-16e2-4682-9212-687036bf60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - load documents\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"https://www.lords.org/getattachment/MCC/All-Laws/2nd-Edition-of-the-2017-code-2019.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1825794e-1e6a-4a71-ba40-5e97502b3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - split documnets into chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a99c9774-2d26-43a3-8fac-a067f98c11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - load documents into Chroma using the open-source embedding function\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bb54331-de1b-4be0-b43c-95909810161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - define the LLM model\n",
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, \n",
    "                 temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df75ddce-2b8b-45e1-8609-f102327de816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - create the chain with the LLM model and the database\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retrievalQA = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=db.as_retriever(), \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f6ee1d3-7d06-4c73-b825-bac7b2e63276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the given context, here is a list of different ways a batsman can get out in cricket:\n",
       "\n",
       "1. Bowled\n",
       "2. Caught\n",
       "3. Stumped\n",
       "4. Hit the ball twice\n",
       "5. LBW (Leg Before Wicket)\n",
       "6. Hit wicket\n",
       "7. Run out\n",
       "8. Obstructing the field\n",
       "\n",
       "Please note that this list may not be exhaustive and there may be other ways a batsman can get out in cricket."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6 - ask the question and display the response!\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "prompt = \"According to given context, create a list of the different ways a batsman can get out\"\n",
    "response = retrievalQA.run(prompt)\n",
    "\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
